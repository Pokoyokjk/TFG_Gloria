{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13a518a9",
   "metadata": {},
   "source": [
    "# Semantic Ethical Glass Box (SEGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fbe5ef",
   "metadata": {},
   "source": [
    "## 1. Overview \n",
    "\n",
    "The Semantic Ethical Glass Box (SEGB) is global *log* storage, which keeps a semantic registry (graph) of logs generated within different systems. It is comprised of two parts: \n",
    "\n",
    "1. A REST API Flask-based server, whose functions are 1) to add new triples to the global graph and 2) retrieve the global graph; \n",
    "\n",
    "2. A MongoDB-based database, where the global graph is storaged in JSON-LD format\n",
    "\n",
    ">[!IMPORTANT]\n",
    "> Since the SEGB is in a testing stage, the MongoDB database is stored in a local Docker-managed volume on the local computer where the SEGB is deployed. In the future, during the deployment stage, the database will be migrated to a centralized server to store all the records in a safe, consistent manner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bd9bed",
   "metadata": {},
   "source": [
    "## 2. API Description\n",
    "\n",
    "### ðŸ”¹ `POST /log`\n",
    "**Description:**  \n",
    "Stores the received **Turtle (TTL)** data, converts it to **JSON-LD**, and saves it in the database. The TTL data could contain one or several triples.\n",
    "\n",
    "#### âœ… Request\n",
    "- **URL:** `/log`\n",
    "- **Method:** `POST`\n",
    "- **Required Headers:** \n",
    "    Content-Type: text/turtle\n",
    "- **Request Body:**  \n",
    "    A document in **Turtle (TTL)** format (`text/turtle`).\n",
    "\n",
    "#### ðŸ“¤ Responses\n",
    "| Status Code | Description |\n",
    "|-------------|-------------|\n",
    "| `200 OK` | Data successfully stored. |\n",
    "| `400 Bad Request` | Error processing data or missing data. |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ `GET /get_graph`\n",
    "**Description:**  \n",
    "Retrieves the stored **JSON-LD** data, processes it, and returns it in **Turtle (TTL)** format.\n",
    "\n",
    "#### âœ… Request\n",
    "- **URL:** `/get_graph`\n",
    "- **Method:** `GET`\n",
    "\n",
    "#### ðŸ“¤ Responses\n",
    "| Status Code | Description |\n",
    "|-------------|-------------|\n",
    "| `200 OK` | Returns the data in **Turtle (TTL)** format. |\n",
    "| `404 Not Found` | No data available in the database. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c5d07d",
   "metadata": {},
   "source": [
    "# 3. Launching the Semantic Ethical Glass Box (SEGB)\n",
    "\n",
    "\n",
    "Use the docker-compose file available in this repository. This action requires access to the image used in the docker compose file. This consists on several steps:\n",
    "\n",
    "1. Get a personal access token to enable console login in ghcr.io (Follow these instructions <https://docs.github.com/es/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens>)\n",
    "\n",
    ">[!CAUTION]\n",
    ">A *classic personal access token* is preferred, given that *fine-grained access* token may cause problems.\n",
    "\n",
    "3. In your console, export your token with:\n",
    "\n",
    "```shell\n",
    "export CR_PAT=<YOUR_TOKEN>\n",
    "```\n",
    "\n",
    "4. Now, login in ghcr.io with:\n",
    "\n",
    "```shell\n",
    "echo $CR_PAT | docker login ghcr.io -u <YOUR_USER_NAME> --password-stdin\n",
    "```\n",
    "\n",
    "5. Finally, execute docker compose in the directory you have your docker-compose.yaml file:\n",
    "\n",
    "```shell\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "6. The URL of the SEGB is `http://127.0.0.1:5000`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817cc02b",
   "metadata": {},
   "source": [
    "## 4. Sending data to and retrieving data from the SEGB within the AMOR context.\n",
    "\n",
    ">[!IMPORTANT]\n",
    ">We strongly recommend to do **NOT use blank nodes** in any triples you want to log in the SEGB. They will not break the SEGB, but it can generate duplicated blank nodes (in the global graph) if they are sent several times to the SEGB due to external limitatios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958c8d58",
   "metadata": {},
   "source": [
    "We have defined a *Python* script, [segb_tutorial.py](./segb_tutorial.py) which defines an SEGB's use case within the AMOR context. \n",
    "\n",
    "It first defines two functions, both of them including console *logs* and some errors verification logic, and being appropiately described by using *Docstring*:\n",
    "\n",
    "- ***log_ttl***: function who receives as *input* the server's URL and the TTL file path and makes a POST to the SEGB.\n",
    "\n",
    "- ***get_graph***: function who receives as *input* the server's URL and the output TTL file path and makes a GET to the SEGB.\n",
    "\n",
    "\n",
    "The workflow defined within the *script* defines the use case as follows:\n",
    "\n",
    "1. First, the server's URL and the TTL files' routes with the different ontologies used (stored in the [example_data](./example-data/) directory in this repo) are defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c08b9c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "server = \"http://127.0.0.1:5000\"\n",
    "    \n",
    "models = [\n",
    "    \"example-data/amor.ttl\",\n",
    "    \"example-data/mft.ttl\",\n",
    "    \"example-data/bhv.ttl\",\n",
    "    \"example-data/amor-mft.ttl\",\n",
    "    \"example-data/amor-bhv.ttl\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6bec5a",
   "metadata": {},
   "source": [
    "2. Next, the *log_ttl* and *get_graph* are defined: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "960b954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "834cd8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_ttl(server: str, input_file_path: str):\n",
    "    \n",
    "    \"\"\"Log a TTL file to the SEGB.\n",
    "\n",
    "    Reads a Turtle (TTL) file from the specified path and sends its content\n",
    "    to the SEGB's `/log` endpoint via a POST request.\n",
    "\n",
    "    Args:\n",
    "        server (str): The base URL of the SEGB server (e.g., \"http://127.0.0.1:5000\").\n",
    "        input_file_path (str): The path to the TTL file to be logged.\n",
    "    \n",
    "    Example:\n",
    "        >>> log_ttl(\"http://127.0.0.1:5000\", \"/path/to/file/data.ttl\")\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(input_file_path, mode=\"r\", encoding=\"utf-8\") as file:\n",
    "        data = file.read()\n",
    "        print(\"File successfully read from:\", input_file_path)\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"text/turtle\"\n",
    "    }\n",
    "    \n",
    "    response = requests.post(f\"{server}/log\", headers=headers, data=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(\"POST request completed successfully\")\n",
    "    else:\n",
    "        print(f\"Error in POST: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cee38f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(server: str, output_file_path: str):\n",
    "    \"\"\"Download the complete graph stored in the SEGB.\n",
    "\n",
    "    Sends a GET request to the SEGB's `/get_graph` endpoint to retrieve the\n",
    "    complete graph in Turtle format and saves it to the specified output file.\n",
    "\n",
    "    Args:\n",
    "        server (str): The base URL of the SEGB server (e.g., \"http://127.0.0.1:5000\").\n",
    "        output_file_path (str): The path where the downloaded graph will be saved.\n",
    "    \n",
    "    Example:\n",
    "        >>> get_graph(\"http://127.0.0.1:5000\", \"/path/to/output/graph.ttl\")\n",
    "    \"\"\"\n",
    "    print(\"Requesting graph...\")\n",
    "    \n",
    "    response = requests.get(f\"{server}/get_graph\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(output_file_path, mode=\"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(response.text)\n",
    "        print(\"File successfully downloaded to:\", output_file_path)\n",
    "\n",
    "    else:\n",
    "        print(f\"Error in GET: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccddb948",
   "metadata": {},
   "source": [
    "3. The ontologies TTL files are mapped to the SEGB's global graph via the *log_ttl* function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da017bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully read from: example-data/amor.ttl\n",
      "POST request completed successfully\n",
      "File successfully read from: example-data/mft.ttl\n",
      "POST request completed successfully\n",
      "File successfully read from: example-data/bhv.ttl\n",
      "POST request completed successfully\n",
      "File successfully read from: example-data/amor-mft.ttl\n",
      "POST request completed successfully\n",
      "File successfully read from: example-data/amor-bhv.ttl\n",
      "POST request completed successfully\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    log_ttl(server, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf30aa",
   "metadata": {},
   "source": [
    "4. A new ontology can be uptated whenever we need it, so we upload a new ontology (in this case, plenty of individuals):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b639537b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully read from: example-data/amor-examples.ttl\n",
      "POST request completed successfully\n"
     ]
    }
   ],
   "source": [
    "input_ttl_file = \"example-data/amor-examples.ttl\"\n",
    "log_ttl(server, input_ttl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff6584d",
   "metadata": {},
   "source": [
    "5.  The same way, we can upload non-ontology TTL files (ideally representing TLL-parsed logs from differents systems, e.g., social robots):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9562c66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully read from: example-data/new-triples.ttl\n",
      "POST request completed successfully\n"
     ]
    }
   ],
   "source": [
    "input_ttl_file = \"example-data/new-triples.ttl\"\n",
    "log_ttl(server, input_ttl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c7cffc",
   "metadata": {},
   "source": [
    "6. We finally retrieve the global graph in TTL format, which includes all the mapped ontologies and all the logs which previously were uploaded, using the *get_graph* function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09e34820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting graph...\n",
      "File successfully downloaded to: graph.ttl\n"
     ]
    }
   ],
   "source": [
    "output_ttl_file = \"graph.ttl\"\n",
    "get_graph(server, output_ttl_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
